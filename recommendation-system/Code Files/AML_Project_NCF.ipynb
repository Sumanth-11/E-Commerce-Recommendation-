{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML-Project-NCF.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fDJDaCof5vM"
      },
      "source": [
        "\n",
        "import json\n",
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4OB6gKQd_P1"
      },
      "source": [
        "\n",
        "#reading from a zip file\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'r')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "a=parse('AMAZON_FASHION_5.json.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YX57wHTjUiX"
      },
      "source": [
        "a=list(a)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOXIG0dYMhD7"
      },
      "source": [
        "# import the dataset\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('AMAZON_FASHION_5.json.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8kgxo1SMwan"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwP2ryRq7Dim"
      },
      "source": [
        "# adding time value to the reviewTime to make the data unique as the the original reviewTime has the same date value for all the products of a particular customer\n",
        "df['reviewTime'] = pd.to_datetime(df['reviewTime'])\n",
        "hrs = pd.Timedelta(hours=9)\n",
        "min = pd.to_timedelta(df.groupby('reviewTime').cumcount().add(1).mul(7), unit='s')\n",
        "df['reviewTime']=df['reviewTime'] + hrs + min "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zXGRSo4AZYe"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lejNg6SLCeep"
      },
      "source": [
        "# Here the reviewerID is filtered according to reviewTime, we are considering this to split our data into train and test. \n",
        "#Test will have the recent timestamp value data and the train will have everything other than the recent timestamp.\n",
        "df['rank_latest']= df.groupby(['reviewerID'])['reviewTime'].rank(method='first', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjghBiKqeLS3"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RW21bDAC1o9"
      },
      "source": [
        "# Here we are splitting the data according to the above timestamp condition \n",
        "train_data = df[df['rank_latest'] != 1]\n",
        "test_data = df[df['rank_latest'] == 1]\n",
        "\n",
        "# drop columns that we no longer need\n",
        "train_data = train_data[['reviewerID', 'asin', 'overall']]\n",
        "test_data = test_data[['reviewerID', 'asin', 'overall']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p958C7DbFo8y"
      },
      "source": [
        "train_data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mChgO42Y3qk4"
      },
      "source": [
        "# We will only consider implicit ratings here from the above explicit ones. Thus, converting all the ratings of the user with that item as 1. \n",
        "# Where 1 represents that the user has interacted with that item.\n",
        "train_data.loc[:, 'overall'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-tQkNqx4DqU"
      },
      "source": [
        "train_data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0PXv6v9GtsG"
      },
      "source": [
        "**We also require negative samples to train our models, to indicate items that the user has not interacted with. We assume that such items are those that the user are not interested in. For now we randomly assign 5 such negative samples for each user-item pair.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xn23QQLdIVw"
      },
      "source": [
        "# Get a list of all product IDs\n",
        "all_pids = df['asin'].unique()\n",
        "\n",
        "# Pointers that will hold the training data\n",
        "users, items, labels = [], [], []\n",
        "\n",
        "# This is the set of items that each user has interaction with\n",
        "user_item_set = set(zip(train_data['reviewerID'], train_data['asin']))\n",
        "\n",
        "# 5:1 ratio of negative to positive samples\n",
        "num_negatives = 5\n",
        "\n",
        "for (u, i) in user_item_set:\n",
        "    users.append(u)\n",
        "    items.append(i)\n",
        "    labels.append(1) # items that the user has interacted with are positive\n",
        "    for _ in range(num_negatives):\n",
        "        # randomly select an item\n",
        "        negative_item = np.random.choice(all_pids) \n",
        "        # check that the user has not interacted with this item\n",
        "        while (u, negative_item) in user_item_set:\n",
        "            negative_item = np.random.choice(all_pids)\n",
        "        users.append(u)\n",
        "        items.append(negative_item)\n",
        "        labels.append(0) # items not interacted with are negative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-EpuCYPdGMl"
      },
      "source": [
        "print(users[:9])\n",
        "print(items[:9])\n",
        "print(labels[:9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsnhlcvnHxZq"
      },
      "source": [
        "**The class below simply encapsulates the code we have written above into a PyTorch Dataset class.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u169-dT-YEVR"
      },
      "source": [
        "class AmazonTrainDataset(Dataset):\n",
        "\n",
        "    def __init__(self, ratings, all_pids):\n",
        "        self.users, self.items, self.labels = self.get_dataset(ratings, all_pids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.labels[idx]\n",
        "\n",
        "    def get_dataset(self, ratings, all_pids):\n",
        "        users, items, labels = [], [], []\n",
        "        user_item_set = set(zip(ratings['reviewerID'], ratings['asin']))\n",
        "\n",
        "        num_negatives = 5\n",
        "        for u, i in user_item_set:\n",
        "            users.append(u)\n",
        "            items.append(i)\n",
        "            labels.append(1)\n",
        "            for _ in range(num_negatives):\n",
        "                negative_item = np.random.choice(all_pids)\n",
        "                while (u, negative_item) in user_item_set:\n",
        "                    negative_item = np.random.choice(all_movieIds)\n",
        "                users.append(u)\n",
        "                items.append(negative_item)\n",
        "                labels.append(0)\n",
        "\n",
        "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}